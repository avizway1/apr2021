D: 21/04/2021

S3 : Simple Storage Service : Object Based storage : Amazon Version of Google Drive

Object Based Storage : We can store the objects, We cannot install any OS, We cannot run any programs. : S3
Block Based Storage : THis is designed to run OS / Programs. : EBS, Instance Store
Storage Over Network : (SAN/ NAS) : RUns over the network and shares to the network running resources.  --> EFS , FSx


--> We store data in Buckets.
--> Bucket = FOlder/Dir with Unique namespace.
--> We have Unlimited data in S3.
--> No Pre-Provisioning required. Pay-as-you-go.

Bucket Naming rules: 
--> Bucket name should be unique.
--> Min Char : 3, Max 63 Char
--> No Capital Letters, No Special Char
--> Should contains .  numbers, Hypens.
--> No Adjesent ..
--> Should not start with . / should not end with .
--> Should not resemble IP Address format. (192.168.0.100)

--> We can upload objects to the s3 bucket.
--> Min Object size 0 bytes.. Max Size 5 TB.

--> S3/IAM is global service, Does not required any region selection.

--> We can create Max of 1000 buckets per account, Soft limit is 100. Raise support ticket to increase the bucket limit.

FREE TIER :
--> 5 gb "S3-Standard Storage"
--> 2000 PUT Requests
--> 20,000 GET Requests


S3 Standard :  Default Storage class, Frequently accessed data.. 
Availability : 99.99%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : >=3 AZ

S3 Standard-IA : Designed to store less frequently accessed data.. Data availabile immediately.. 
Availability : 99.9%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : >=3 AZ

S3 Onezone-IA : Designed to store less frequently accessed data.. Data availabile immediately..  40% less cost than Standard-IA..
Availability : 99.5%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : 1 AZ

S3 Glacier : Disigned to archieve the data.. Data will not be availabile immediately..
We need to initialise restoration to get the data.. Data Retrival takes Minutes to Hours.. 
Availability : 99.99%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : >=3 AZ

S3 Glacier Deep Archieve : Disigned to archieve the data.. Data will not be availabile immediately..
We need to initialise restoration to get the data.. Data Retrival takes Hours.. 
Availability : 99.99%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : >=3 AZ

S3 Interlligent Tiering : When we don't have predictable access patterns, We can choose this..
Availability : 99.9%
Durability : 99.999999999% (11 9's)
Data Spread across AZs : >=3 AZ

S3 - RRS : Redused Redundancy Storage : Durability is very less : 99.99%, So not recommended to use. Logs, thumbnails.. Easily Reprodusable data.. !!

_______________________________________________________________________________________

D: 22/04/2021

Standard Object URL : 
https://s3.ap-south-1.amazonaws.com/avinash.1231/iam.txt
https://s3.regioncode.amazonaws.com/bucketname/objectname

Virtual path : Works when we don;t have . in the bucket name
https://avinash.s3.ap-south-1.amazonaws.com/iam.txt
https://bucketname.s3.regioncode.amazonaws.com/objectname

Block all public access : On .. If we want to make any data puboic accesable, We need to turn this off first, Then edit the object level settings.

Versioning : Keeps track/monitor changes on objects.
--> If we accidentally delete the object, we can get the object back.
--> We will have current versioned object and previous verisoned objects.
--> When we delete Latest/cusrrent version object we will get Delete Marker. Delete the Delete marker to get the object back. (Version : hide)
--> TO get the object back, Set "Version : Show", Then delete the Delete Marker.
--> For Previous versioned objects, If we delete, we don;t get any Delete marker.

permanently delete : Objects permanently deletes
delete : It will gives us Delete Marker.

Cross Region Replication (Crr) / Same region replication (srr) :  
--> Source bucket and destination bucket shoud enable with versioning.
--> Be fore enable, Replication whatever the data we have it won't replicate to destination bucket. (Onetime, We can perform copy and paste/ Run "Sync" command)

Tags : Metadata for the resources.

Server Access Logging : If you want to enable logging on individual bucket. 

_______________________________________________________________________________________
D: 23/04/2021

Life Cycle Management rule : We can automatically trasit objects from one storage class to another storage class.
** Refer the Image.

Task : Create a bucket, Upload the data.. Current version data and previous version data shuld delete immedeate next day. 

___

ENcryption : 

Free Tier : ss3-s3 , aws/s3

In-Transit Encryption : No need to worry about this
	--> https : ssl / tls 

At-Rest Encryption / Server Side Encryption (SSE) : 

--> SSE-S3 :  S3 service will generate the encryption keys. Whoever have the access on s3 platform he can decrypt/view the data. 
--> SSE-KMS (Key Management Service):  
	--> aws/s3 : KMS service will generate the encryption keys. Whoever have the access on s3 platform he can decrypt/view the data.
	--> kms/cmk (Customer Managed key): KMS service will generate the encryption keys. Whoever have valid permissions on Encryption key and s3, only they can access the data.

--> SSE-C : Customer need to generate the encryption key material and he need to upload it to KMS. Whoever have valid permissions on Encryption key and s3, only they can access the data.


Client Side Encryption : Before uploading the data to s3 plartform, We can encrypt the data in local environment. Client is responsible for this encryption/decryption.


Key type : Symmetric : 
Symmetric : A single encryption key that is used for both encrypt and decrypt operations
Asymmetric : A public and private key pair that can be used for encrypt/decrypt or sign/verify operations

--> Key administrators : WHo can Administrate / manage this key (Delete/allocating permisisons to another users).

--> Key usage permissions : Who can use this key. Who can decrypt the data.

_______________________________________________________________________________________

D: 26/04/2021

Requirement : Allow full access on s3 platform, But not on 1 bucket. Deny PUT operation (upload) on this specific bucket. 

Bucket policy : Writtens in JSON format.	

ARN : Amazon Resource Name

Bucket ARN : arn:aws:s3:::user1.bucket231

https://awspolicygen.s3.amazonaws.com/policygen.html

Effect : ALLOW / DENY 		: Deny
Principal : IAM User/Group 	: arn:aws:iam::518084852393:user/user1
to whom you want to take deny/allow operation

Action : PUt Object

Amazon Resource Name (ARN) :
On what resource you want to apply these actions for the principal users/groups.


Bucket Level Operation : arn:aws:s3:::user1.bucket231
Object level operation : arn:aws:s3:::user1.bucket231/*

______

Intelligent-Tiering Archive configurations : 

Intelligent Tier Archive Access tier
When enabled, Intelligent-Tiering will automatically move objects that havenâ€™t been accessed for a minimum of 90 days to the Archive Access tier.
____

Event notifications : When any defined event happened on s3 bucket, we can get notifications.
--> SQS
--> SNS : Simple Notification Service.
--> Lambda

SNS : Create a topic, Add subnscribers to the topic, We can send email to all the subscribers.

____

Transfer acceleration : We can use edge locations to upload/download the data for this bucket. 
** If we want to use this feature, Bucket name should not contain .
For gui/browser, AWS users endpoint automatically if we enable.
FOr cli : We need to define "--endpoint avinash.s3-accelerate.amazonaws.com" 

http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html

_____

Static website hosting : S3 platform supports static website only.

DOmain Name should be same as bucket name, if future if you want to map a domain name.
(Route53)

http://avinash.com.s3-website.ap-south-1.amazonaws.com

http status codes :

2XX : OK/Success
3XX : Redirections
4XX : Client side error
5XX : Server Side error

https://www.free-css.com/free-css-templates

______________________________________________________________________________________

D: 27/04/2021

Object Lock : Protect the data. 
--> Versioning must be enable if we want to use object lock.

Governance : Users with specific IAM permissions can overwrite or delete protected object versions during the retention period.

Compliance : No users can overwrite or delete protected object versions during the retention period. Including root user.

__

Access control list (ACL) : 

aws s3 ls s3://publicbucket	--> List all the data from bucket

--> S3Broswer, Cyberduck, winscp, cloudberry explorer

Cananical id : Designed to share s3 buckets with nother aws accounts. 

___

Cross-origin resource sharing (CORS) : 

CLoudwatch : Monitoring service in AWS.

Storage Class Analysis : Gives storage class, and access patterns report of this bucket.

Inventory configurations : we will get complete inventory report of this s3 bucket objects. (Daily, weekly).

___

What perf we can expect from s3 bucket.?

Every Single prefix will the below perf:
3500 PUT/Copy/post/delete Operations per Second.
5500 GET/Head Operations per Second

--> If we required a bucket with 55,000 GET operation, Create 10 Prefixes in bucket.

--> Use Prefixes, and Increase the randomness in the object name for the best performance.

___

Read-after-write consistency for PUT of new Object and Delete of an Object.

If we upload any data to s3, if you try to list, it will be available immedetely/.
If we delete, If won't show.

Eventual consistency for Delete an Bucket.
--> If you delete a bucket and immediately list all bucket command executed, The deleted bucket may appear in the list.

___

Import/export large data to s3 platform. 

--> Amazon Snowcone, Snowball edge, snowmobile : 
8 tb snowcone,
40-100 TB Snowball edge..
10 pb data : snowmobile

1 pb data with 1 gbps internet line with 80% internet utilisation : 20-23 Yrs to upload data

___









































































